{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-17T00:58:48.295540Z",
     "start_time": "2024-03-17T00:58:48.288492Z"
    }
   },
   "outputs": [],
   "source": [
    "packages_to_install = {\n",
    "    \"ipywidgets\": \"ipywidgets\",\n",
    "    \"numpy\": \"numpy=1.24.0\",\n",
    "    \"torch\": \"torch\",\n",
    "    \"matplotlib\": \"matplotlib\",\n",
    "    \"sentencepiece\": \"sentencepiece\",\n",
    "    \"protobuf\": \"protobuf\",\n",
    "    \"datasets\": \"datasets\",\n",
    "    \"transformers\": \"transformers\",\n",
    "    \"diffusers\": \"diffusers\",\n",
    "    \"peft\": \"peft\",\n",
    "    \"h5py\": \"h5py\",\n",
    "    \"scikit-learn\": \"scikit-learn\",\n",
    "    \"scipy\": \"scipy\",\n",
    "    \"wandb\": \"wandb\",\n",
    "    \"mwparserfromhell\": \"mwparserfromhell\",\n",
    "    \"apache_beam\": \"apache_beam\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipywidgets is already installed.\n",
      "numpy is already installed.\n",
      "torch is already installed.\n",
      "matplotlib is already installed.\n",
      "sentencepiece is already installed.\n",
      "protobuf is not installed. Installing it now...\n",
      "Retrieving notices: ...working... done\r\n",
      "Collecting package metadata (current_repodata.json): - WARNING conda.models.version:get_matcher(556): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.*, but conda is ignoring the .* and treating it as 1.7.1\r\n",
      "done\r\n",
      "Solving environment: done\r\n",
      "\r\n",
      "\r\n",
      "==> WARNING: A newer version of conda exists. <==\r\n",
      "  current version: 23.7.4\r\n",
      "  latest version: 24.1.2\r\n",
      "\r\n",
      "Please update conda by running\r\n",
      "\r\n",
      "    $ conda update -n base -c conda-forge conda\r\n",
      "\r\n",
      "Or to minimize the number of packages updated during conda update use\r\n",
      "\r\n",
      "     conda install conda=24.1.2\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "# All requested packages already installed.\r\n",
      "\r\n",
      "datasets is already installed.\n",
      "transformers is already installed.\n",
      "diffusers is already installed.\n",
      "peft is already installed.\n",
      "h5py is already installed.\n",
      "scikit-learn is not installed. Installing it now...\n",
      "Collecting package metadata (current_repodata.json): - WARNING conda.models.version:get_matcher(556): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.*, but conda is ignoring the .* and treating it as 1.7.1\r\n",
      "done\r\n",
      "Solving environment: done\r\n",
      "\r\n",
      "\r\n",
      "==> WARNING: A newer version of conda exists. <==\r\n",
      "  current version: 23.7.4\r\n",
      "  latest version: 24.1.2\r\n",
      "\r\n",
      "Please update conda by running\r\n",
      "\r\n",
      "    $ conda update -n base -c conda-forge conda\r\n",
      "\r\n",
      "Or to minimize the number of packages updated during conda update use\r\n",
      "\r\n",
      "     conda install conda=24.1.2\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "# All requested packages already installed.\r\n",
      "\r\n",
      "scipy is already installed.\n",
      "wandb is already installed.\n",
      "mwparserfromhell is already installed.\n",
      "apache_beam is not installed. Installing it now...\n",
      "Collecting package metadata (current_repodata.json): - WARNING conda.models.version:get_matcher(556): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.*, but conda is ignoring the .* and treating it as 1.7.1\r\n",
      "done\r\n",
      "Solving environment: unsuccessful initial attempt using frozen solve. Retrying with flexible solve.\r\n",
      "Collecting package metadata (repodata.json): \\ WARNING conda.models.version:get_matcher(556): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.6.0.*, but conda is ignoring the .* and treating it as 1.6.0\r\n",
      "WARNING conda.models.version:get_matcher(556): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.9.0.*, but conda is ignoring the .* and treating it as 1.9.0\r\n",
      "WARNING conda.models.version:get_matcher(556): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.8.0.*, but conda is ignoring the .* and treating it as 1.8.0\r\n",
      "done\r\n",
      "Solving environment: unsuccessful initial attempt using frozen solve. Retrying with flexible solve.\r\n",
      "\r\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\r\n",
      "\r\n",
      "  - apache_beam\r\n",
      "\r\n",
      "Current channels:\r\n",
      "\r\n",
      "  - https://conda.anaconda.org/conda-forge/linux-64\r\n",
      "  - https://conda.anaconda.org/conda-forge/noarch\r\n",
      "  - https://repo.anaconda.com/pkgs/main/linux-64\r\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\r\n",
      "  - https://repo.anaconda.com/pkgs/r/linux-64\r\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\r\n",
      "\r\n",
      "To search for alternate channels that may provide the conda package you're\r\n",
      "looking for, navigate to\r\n",
      "\r\n",
      "    https://anaconda.org\r\n",
      "\r\n",
      "and use the search bar at the top of the page.\r\n",
      "\r\n",
      "\r\n",
      "CPU times: user 5.77 s, sys: 1.7 s, total: 7.47 s\n",
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import importlib\n",
    "\n",
    "for package_name, install_command in packages_to_install.items():\n",
    "    try:\n",
    "        importlib.import_module(package_name)\n",
    "        print(f\"{package_name} is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"{package_name} is not installed. Installing it now...\")\n",
    "        !conda install -y {install_command}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T01:02:29.658312Z",
     "start_time": "2024-03-17T00:58:48.297262Z"
    }
   },
   "id": "62f543449a0b33f2",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T01:02:29.663871Z",
     "start_time": "2024-03-17T01:02:29.660217Z"
    }
   },
   "id": "8ce764012d7341a5",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build Dataset\n",
    "\n",
    "## Training Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5decc93e4e11cfa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "qu_data = load_dataset(\"wikipedia\", language=\"qu\", date=\"20240301\", trust_remote_code=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T01:09:52.761786Z",
     "start_time": "2024-03-17T01:09:50.647440Z"
    }
   },
   "id": "5d7df955695099a6",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "filtered_dataset = qu_data.filter(lambda example: len(example['text']) <= 2048)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T01:10:40.802274Z",
     "start_time": "2024-03-17T01:10:40.795356Z"
    }
   },
   "id": "3764ab4ca1d44a2d",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "shuffled_dataset = filtered_dataset.shuffle(seed=42)\n",
    "filtered_dataset = shuffled_dataset[\"train\"].select(range(2500))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T01:10:41.469969Z",
     "start_time": "2024-03-17T01:10:41.462310Z"
    }
   },
   "id": "e2e14b27a5a4ace",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MODEL_NAME = \"facebook/xglm-564M\" # specify model name\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, device_map = 'cuda')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"])\n",
    "\n",
    "tokenized_qu_data = filtered_dataset.map(tokenize_function, batched=True, num_proc=8, remove_columns=filtered_dataset.column_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T01:10:45.635495Z",
     "start_time": "2024-03-17T01:10:43.454578Z"
    }
   },
   "id": "bb9d3cf9a42705c3",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "block_size = 128\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T01:10:48.955263Z",
     "start_time": "2024-03-17T01:10:48.951142Z"
    }
   },
   "id": "63e4d0239df7aca9",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map (num_proc=8):   0%|          | 0/2500 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b0c6332fe183421fbadc7be3da3985eb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_datasets = tokenized_qu_data.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=64,\n",
    "    num_proc=8,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T01:55:36.710623Z",
     "start_time": "2024-03-17T01:55:36.345441Z"
    }
   },
   "id": "a2429d9429c8c326",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\"m) 153 km Yunkay (2.500 m) 163 km Qaras (2.290 m) 205 km Wallanka (1.820 m) 215 km Yuramarka (1.420 m) 343 km Santa (20 m) Kaypipas qhaway Patu Wayq'u Waylas Pukyukuna Instituto Nacional Geográfico Mayu (Piruw) Mayu (Anqash suyu) Mayu (Qispi kay suyu) Rikuway pruwinsya Santa pruwinsya Waras pruwinsya Waylas pruwinsya</s> Nonato Rufino Chuquimamani Valer sutiyuq runaqa (1946 watapi pa\""
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[1][\"input_ids\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T01:55:38.023342Z",
     "start_time": "2024-03-17T01:55:38.016031Z"
    }
   },
   "id": "8cb56126472e10aa",
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validation Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb774566d7209f01"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "DATA_SET_NAME = \"facebook/flores\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T01:55:39.295328Z",
     "start_time": "2024-03-17T01:55:39.291974Z"
    }
   },
   "id": "9f07a8a90c3016de",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# specify languages\n",
    "LANGUAGES = [\n",
    "    \"eng_Latn\",\n",
    "    \"spa_Latn\",\n",
    "    \"ita_Latn\",\n",
    "    \"deu_Latn\",\n",
    "    \"arb_Arab\",\n",
    "    \"tel_Telu\",\n",
    "    \"tam_Taml\",\n",
    "    \"quy_Latn\"\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T01:55:39.679407Z",
     "start_time": "2024-03-17T01:55:39.676387Z"
    }
   },
   "id": "ec5d9a86abdf3ec7",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load flores data for each language\n",
    "# TODO: your code goes here\n",
    "multilang_dataset = {}\n",
    "for language in LANGUAGES:\n",
    "    multilang_dataset[language] = load_dataset(DATA_SET_NAME, language, trust_remote_code=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T01:55:59.721790Z",
     "start_time": "2024-03-17T01:55:40.406137Z"
    }
   },
   "id": "42d9e1ef730c40b3",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# tokenize the data\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# load a pre-trained tokenizer from the huggingface hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, device_map = 'cuda')\n",
    "\n",
    "# specify the tokenization function\n",
    "def tokenization(example):\n",
    "    return tokenizer(example['sentence'])\n",
    "\n",
    "# TODO: your code goes here\n",
    "tokenization(multilang_dataset[\"eng_Latn\"][\"dev\"])\n",
    "tokenized_multilang_dataset = {}\n",
    "for key, data in multilang_dataset.items():\n",
    "    tokenized_multilang_dataset[key] = data.map(tokenization, batched=True)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T01:56:03.063850Z",
     "start_time": "2024-03-17T01:55:59.723269Z"
    }
   },
   "id": "d69d223eca7b1872",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for key, data in tokenized_multilang_dataset.items():\n",
    "    tokenized_multilang_dataset[key] = tokenized_multilang_dataset[key][\"dev\"].remove_columns([\"id\", \"URL\", \"domain\", \"topic\", \"has_image\", \"has_hyperlink\", \"sentence\"])\n",
    "    tokenized_multilang_dataset[key].set_format(\"torch\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T01:56:03.080172Z",
     "start_time": "2024-03-17T01:56:03.065505Z"
    }
   },
   "id": "9239e764706089de",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'eng_Latn': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n }),\n 'spa_Latn': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n }),\n 'ita_Latn': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n }),\n 'deu_Latn': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n }),\n 'arb_Arab': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n }),\n 'tel_Telu': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n }),\n 'tam_Taml': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n }),\n 'quy_Latn': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n })}"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_multilang_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T01:56:03.086973Z",
     "start_time": "2024-03-17T01:56:03.082504Z"
    }
   },
   "id": "9aa1dd114ca62bea",
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # construct a pytorch data loader for each dataset\n",
    "# BATCH_SIZE = 2 # for testing purposes, we start with a batch size of 2. You can change this later.\n",
    "\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# # random_test_dataloader = DataLoader(random_test_dataset, batch_size=1, shuffle=False)\n",
    "# # for i,data in random_test_dataloader:\n",
    "# #     print(i)\n",
    "\n",
    "# def make_dataloaders(multilang_dataset):\n",
    "#     dataloaders_dict = {}\n",
    "#     for key, dataset_dict in multilang_dataset.items():\n",
    "#         dataloaders_dict[key] = {\"dev\":DataLoader(multilang_dataset[key][\"dev\"], batch_size=BATCH_SIZE, collate_fn=data_collator, shuffle = True),\n",
    "#                                  \"devtest\": DataLoader(multilang_dataset[key][\"devtest\"], batch_size=BATCH_SIZE, collate_fn=data_collator, shuffle = True)}\n",
    "#     return dataloaders_dict\n",
    "\n",
    "# dataloaders_dict = make_dataloaders(tokenized_multilang_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T01:56:03.096327Z",
     "start_time": "2024-03-17T01:56:03.088280Z"
    }
   },
   "id": "90c4bda2c0489c81",
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af0069e162d925fb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T01:56:03.107229Z",
     "start_time": "2024-03-17T01:56:03.097977Z"
    }
   },
   "id": "9e2f2161aaa24326",
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load pre-trained model from the huggingface hub\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map = 'cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T01:56:05.043301Z",
     "start_time": "2024-03-17T01:56:03.108786Z"
    }
   },
   "id": "2a2083942a185807",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "XGLMForCausalLM(\n  (model): XGLMModel(\n    (embed_tokens): Embedding(256008, 1024, padding_idx=1)\n    (embed_positions): XGLMSinusoidalPositionalEmbedding()\n    (layers): ModuleList(\n      (0-23): 24 x XGLMDecoderLayer(\n        (self_attn): XGLMAttention(\n          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        )\n        (activation_fn): GELUActivation()\n        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=1024, out_features=256008, bias=False)\n)"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T01:56:05.052699Z",
     "start_time": "2024-03-17T01:56:05.045781Z"
    }
   },
   "id": "f0a08d6622443770",
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bitfit:\n",
    "### Version 1:\n",
    "turns off params param.requires_grad = False\n",
    "turns on biases required_grad = True\n",
    "\n",
    "### Version 2:\n",
    "turns off params\n",
    "Trains only biases with high gradients"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7db8424daf6e086f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Version 2: Only biases with high gradients are trained"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3aea1aead190a93c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "names = [\"final_layer_norm.bias\", \"self_attn_layer_norm.bias\", \"model.layer_norm.bias\"]\n",
    "for i in model.named_parameters():\n",
    "    for name in names:\n",
    "        if name in i[0]:\n",
    "            i[1].requires_grad = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T01:56:08.033799Z",
     "start_time": "2024-03-17T01:56:08.028441Z"
    }
   },
   "id": "e928026a03365dba",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "387\n"
     ]
    }
   ],
   "source": [
    "a = [param.requires_grad for param in model.parameters()]\n",
    "print(sum(a))\n",
    "print(len(a))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T01:56:09.289342Z",
     "start_time": "2024-03-17T01:56:09.284593Z"
    }
   },
   "id": "878716567fd3db7f",
   "execution_count": 69
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a4cfd689cef7525"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"] = \"XGLM finetuning\"  # name your W&B project\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n",
    "os.environ[\"WANDB_WATCH\"]=\"all\"\n",
    "# os.environ[\"WANDB_SILENT\"]=\"true\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T01:56:12.098057Z",
     "start_time": "2024-03-17T01:56:12.094134Z"
    }
   },
   "id": "94eeefe1db14d62d",
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"finetuned-bitfit-two\",\n",
    "    evaluation_strategy = \"steps\",\n",
    "    eval_steps=200,\n",
    "    save_total_limit=2,\n",
    "    save_steps=200,\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    report_to=[\"wandb\"],\n",
    "    run_name=\"BITFIT_TWO_1\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    metric_for_best_model=\"quy_Latn_loss\",\n",
    "    num_train_epochs=3,\n",
    "    gradient_accumulation_steps=4,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T02:01:10.456172Z",
     "start_time": "2024-03-17T02:01:10.451389Z"
    }
   },
   "id": "5f945cd895c91a54",
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets,\n",
    "    eval_dataset=tokenized_multilang_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T02:01:11.151126Z",
     "start_time": "2024-03-17T02:01:11.143186Z"
    }
   },
   "id": "8e3adecc7a1b4a69",
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='201' max='264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [201/264 14:20 < 04:32, 0.23 it/s, Epoch 2.27/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Eng Latn Loss</th>\n      <th>Spa Latn Loss</th>\n      <th>Ita Latn Loss</th>\n      <th>Deu Latn Loss</th>\n      <th>Arb Arab Loss</th>\n      <th>Tel Telu Loss</th>\n      <th>Tam Taml Loss</th>\n      <th>Quy Latn Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>5.276800</td>\n      <td>No log</td>\n      <td>5.123478</td>\n      <td>4.719269</td>\n      <td>4.766665</td>\n      <td>4.792190</td>\n      <td>4.885338</td>\n      <td>4.505744</td>\n      <td>4.322783</td>\n      <td>6.760704</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='225' max='264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [225/264 19:59 < 03:29, 0.19 it/s, Epoch 2.55/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Eng Latn Loss</th>\n      <th>Spa Latn Loss</th>\n      <th>Ita Latn Loss</th>\n      <th>Deu Latn Loss</th>\n      <th>Arb Arab Loss</th>\n      <th>Tel Telu Loss</th>\n      <th>Tam Taml Loss</th>\n      <th>Quy Latn Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>5.276800</td>\n      <td>No log</td>\n      <td>5.123478</td>\n      <td>4.719269</td>\n      <td>4.766665</td>\n      <td>4.792190</td>\n      <td>4.885338</td>\n      <td>4.505744</td>\n      <td>4.322783</td>\n      <td>6.760704</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='265' max='264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [264/264 23:10, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Eng Latn Loss</th>\n      <th>Spa Latn Loss</th>\n      <th>Ita Latn Loss</th>\n      <th>Deu Latn Loss</th>\n      <th>Arb Arab Loss</th>\n      <th>Tel Telu Loss</th>\n      <th>Tam Taml Loss</th>\n      <th>Quy Latn Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>5.276800</td>\n      <td>No log</td>\n      <td>5.123478</td>\n      <td>4.719269</td>\n      <td>4.766665</td>\n      <td>4.792190</td>\n      <td>4.885338</td>\n      <td>4.505744</td>\n      <td>4.322783</td>\n      <td>6.760704</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='264' max='264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [264/264 24:31, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Eng Latn Loss</th>\n      <th>Spa Latn Loss</th>\n      <th>Ita Latn Loss</th>\n      <th>Deu Latn Loss</th>\n      <th>Arb Arab Loss</th>\n      <th>Tel Telu Loss</th>\n      <th>Tam Taml Loss</th>\n      <th>Quy Latn Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>5.276800</td>\n      <td>No log</td>\n      <td>5.123478</td>\n      <td>4.719269</td>\n      <td>4.766665</td>\n      <td>4.792190</td>\n      <td>4.885338</td>\n      <td>4.505744</td>\n      <td>4.322783</td>\n      <td>6.760704</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='87.234 MB of 4349.327 MB uploaded\\r'), FloatProgress(value=0.020056909081894208, m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b86ebdf4654a439ca09d38fdf833ea7f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (TransientError), entering retry loop.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/arb_Arab_loss</td><td>▁</td></tr><tr><td>eval/arb_Arab_runtime</td><td>▁</td></tr><tr><td>eval/arb_Arab_samples_per_second</td><td>▁</td></tr><tr><td>eval/arb_Arab_steps_per_second</td><td>▁</td></tr><tr><td>eval/deu_Latn_loss</td><td>▁</td></tr><tr><td>eval/deu_Latn_runtime</td><td>▁</td></tr><tr><td>eval/deu_Latn_samples_per_second</td><td>▁</td></tr><tr><td>eval/deu_Latn_steps_per_second</td><td>▁</td></tr><tr><td>eval/eng_Latn_loss</td><td>▁</td></tr><tr><td>eval/eng_Latn_runtime</td><td>▁</td></tr><tr><td>eval/eng_Latn_samples_per_second</td><td>▁</td></tr><tr><td>eval/eng_Latn_steps_per_second</td><td>▁</td></tr><tr><td>eval/ita_Latn_loss</td><td>▁</td></tr><tr><td>eval/ita_Latn_runtime</td><td>▁</td></tr><tr><td>eval/ita_Latn_samples_per_second</td><td>▁</td></tr><tr><td>eval/ita_Latn_steps_per_second</td><td>▁</td></tr><tr><td>eval/quy_Latn_loss</td><td>▁</td></tr><tr><td>eval/quy_Latn_runtime</td><td>▁</td></tr><tr><td>eval/quy_Latn_samples_per_second</td><td>▁</td></tr><tr><td>eval/quy_Latn_steps_per_second</td><td>▁</td></tr><tr><td>eval/spa_Latn_loss</td><td>▁</td></tr><tr><td>eval/spa_Latn_runtime</td><td>▁</td></tr><tr><td>eval/spa_Latn_samples_per_second</td><td>▁</td></tr><tr><td>eval/spa_Latn_steps_per_second</td><td>▁</td></tr><tr><td>eval/tam_Taml_loss</td><td>▁</td></tr><tr><td>eval/tam_Taml_runtime</td><td>▁</td></tr><tr><td>eval/tam_Taml_samples_per_second</td><td>▁</td></tr><tr><td>eval/tam_Taml_steps_per_second</td><td>▁</td></tr><tr><td>eval/tel_Telu_loss</td><td>▁</td></tr><tr><td>eval/tel_Telu_runtime</td><td>▁</td></tr><tr><td>eval/tel_Telu_samples_per_second</td><td>▁</td></tr><tr><td>eval/tel_Telu_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>█▇▆▅▄▄▃▄▃▅▄▃▂▂▃▂▂▃▃▂▂▂▂▁▁▁▁▂▂▃▂▁▂▂▂▂▂▁▁▂</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>▇█▆▅▅▄▄▅▃▅▅▅▄▃▄▅▃▄▄▃▅▃▃▃▁▂▄▅▃▃▂▃▂▄▃▄▂▃▄▄</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/arb_Arab_loss</td><td>4.88534</td></tr><tr><td>eval/arb_Arab_runtime</td><td>19.7808</td></tr><tr><td>eval/arb_Arab_samples_per_second</td><td>50.402</td></tr><tr><td>eval/arb_Arab_steps_per_second</td><td>6.319</td></tr><tr><td>eval/deu_Latn_loss</td><td>4.79219</td></tr><tr><td>eval/deu_Latn_runtime</td><td>25.6286</td></tr><tr><td>eval/deu_Latn_samples_per_second</td><td>38.902</td></tr><tr><td>eval/deu_Latn_steps_per_second</td><td>4.877</td></tr><tr><td>eval/eng_Latn_loss</td><td>5.12348</td></tr><tr><td>eval/eng_Latn_runtime</td><td>16.3286</td></tr><tr><td>eval/eng_Latn_samples_per_second</td><td>61.059</td></tr><tr><td>eval/eng_Latn_steps_per_second</td><td>7.655</td></tr><tr><td>eval/ita_Latn_loss</td><td>4.76667</td></tr><tr><td>eval/ita_Latn_runtime</td><td>18.918</td></tr><tr><td>eval/ita_Latn_samples_per_second</td><td>52.701</td></tr><tr><td>eval/ita_Latn_steps_per_second</td><td>6.607</td></tr><tr><td>eval/quy_Latn_loss</td><td>6.7607</td></tr><tr><td>eval/quy_Latn_runtime</td><td>27.2572</td></tr><tr><td>eval/quy_Latn_samples_per_second</td><td>36.577</td></tr><tr><td>eval/quy_Latn_steps_per_second</td><td>4.586</td></tr><tr><td>eval/spa_Latn_loss</td><td>4.71927</td></tr><tr><td>eval/spa_Latn_runtime</td><td>18.7465</td></tr><tr><td>eval/spa_Latn_samples_per_second</td><td>53.183</td></tr><tr><td>eval/spa_Latn_steps_per_second</td><td>6.668</td></tr><tr><td>eval/tam_Taml_loss</td><td>4.32278</td></tr><tr><td>eval/tam_Taml_runtime</td><td>22.9981</td></tr><tr><td>eval/tam_Taml_samples_per_second</td><td>43.351</td></tr><tr><td>eval/tam_Taml_steps_per_second</td><td>5.435</td></tr><tr><td>eval/tel_Telu_loss</td><td>4.50574</td></tr><tr><td>eval/tel_Telu_runtime</td><td>21.9737</td></tr><tr><td>eval/tel_Telu_samples_per_second</td><td>45.372</td></tr><tr><td>eval/tel_Telu_steps_per_second</td><td>5.689</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>264</td></tr><tr><td>train/grad_norm</td><td>0.93046</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>5.2166</td></tr><tr><td>train/total_flos</td><td>1959326290280448.0</td></tr><tr><td>train/train_loss</td><td>5.23924</td></tr><tr><td>train/train_runtime</td><td>1395.8147</td></tr><tr><td>train/train_samples_per_second</td><td>6.046</td></tr><tr><td>train/train_steps_per_second</td><td>0.189</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">BITFIT_TWO_1</strong> at: <a href='https://wandb.ai/aleksey-morshnev/XGLM%20finetuning/runs/jpjif9fw' target=\"_blank\">https://wandb.ai/aleksey-morshnev/XGLM%20finetuning/runs/jpjif9fw</a><br/> View job at <a href='https://wandb.ai/aleksey-morshnev/XGLM%20finetuning/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0OTU4NzY1OQ==/version_details/v0' target=\"_blank\">https://wandb.ai/aleksey-morshnev/XGLM%20finetuning/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0OTU4NzY1OQ==/version_details/v0</a><br/>Synced 6 W&B file(s), 0 media file(s), 22 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20240317_025835-jpjif9fw/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "trainer.train()\n",
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T03:35:35.788508Z",
     "start_time": "2024-03-17T02:01:12.307144Z"
    }
   },
   "id": "3200e80155a75c9c",
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bf905bd239e8e747"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# model.save_pretrained(\"./pretrained_FFT_1\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2acfd6f2d34139d1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efaeae44911271f1",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
