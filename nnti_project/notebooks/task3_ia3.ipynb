{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-17T12:31:32.405536Z",
     "start_time": "2024-03-17T12:31:32.402048Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "import torch\n",
    "from functools import partial\n",
    "import time\n",
    "\n",
    "DATASET = 'hackathon-pln-es/spanish-to-quechua'\n",
    "MODEL_NAME = 'facebook/xglm-564M'\n",
    "SEQ_LEN   = 32"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T12:31:32.483271Z",
     "start_time": "2024-03-17T12:31:32.480131Z"
    }
   },
   "id": "9f63f48fd745b375",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e238d391881b579c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/reni/.cache/huggingface/modules/datasets_modules/datasets/wikipedia/d41137e149b2ea90eead07e7e3f805119a8c22dd1d5b61651af8e3e3ee736001 (last modified on Sat Mar 16 01:09:02 2024) since it couldn't be found locally at wikipedia, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "qu_data = load_dataset(\"wikipedia\", language=\"qu\", date=\"20240301\", trust_remote_code=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T12:31:42.620612Z",
     "start_time": "2024-03-17T12:31:32.484838Z"
    }
   },
   "id": "395054082e8022dd",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "filtered_dataset = qu_data.filter(lambda example: len(example['text']) <= 2048)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T12:31:42.636060Z",
     "start_time": "2024-03-17T12:31:42.622629Z"
    }
   },
   "id": "8870d7dfbc88c1d8",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "shuffled_dataset = filtered_dataset.shuffle(seed=42)\n",
    "filtered_dataset = shuffled_dataset[\"train\"].select(range(2500))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T12:31:42.650709Z",
     "start_time": "2024-03-17T12:31:42.637496Z"
    }
   },
   "id": "abf5ea4a85e84a04",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MODEL_NAME = \"facebook/xglm-564M\" # specify model name\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, device_map = 'cuda')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"])\n",
    "\n",
    "tokenized_qu_data = filtered_dataset.map(tokenize_function, batched=True, num_proc=8, remove_columns=filtered_dataset.column_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T12:31:54.536632Z",
     "start_time": "2024-03-17T12:31:42.652761Z"
    }
   },
   "id": "e31b88e222579583",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "block_size = 128\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T12:31:54.541891Z",
     "start_time": "2024-03-17T12:31:54.538143Z"
    }
   },
   "id": "ffb72a9daa0d35cb",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lm_datasets = tokenized_qu_data.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=8,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T12:31:54.583392Z",
     "start_time": "2024-03-17T12:31:54.543089Z"
    }
   },
   "id": "46d7d5f0a4071fb6",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\"m) 153 km Yunkay (2.500 m) 163 km Qaras (2.290 m) 205 km Wallanka (1.820 m) 215 km Yuramarka (1.420 m) 343 km Santa (20 m) Kaypipas qhaway Patu Wayq'u Waylas Pukyukuna Instituto Nacional GeogrÃ¡fico Mayu (Piruw) Mayu (Anqash suyu) Mayu (Qispi kay suyu) Rikuway pruwinsya Santa pruwinsya Waras pruwinsya Waylas pruwinsya</s> Nonato Rufino Chuquimamani Valer sutiyuq runaqa (1946 watapi pa\""
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[1][\"input_ids\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T12:31:54.590970Z",
     "start_time": "2024-03-17T12:31:54.584686Z"
    }
   },
   "id": "e950b72d6cfb328b",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Validation Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2eaaad066c2f598"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "DATA_SET_NAME = \"facebook/flores\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T12:31:54.599159Z",
     "start_time": "2024-03-17T12:31:54.592196Z"
    }
   },
   "id": "a3771238a12ddb4e",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# specify languages\n",
    "LANGUAGES = [\n",
    "    \"eng_Latn\",\n",
    "    \"spa_Latn\",\n",
    "    \"ita_Latn\",\n",
    "    \"deu_Latn\",\n",
    "    \"arb_Arab\",\n",
    "    \"tel_Telu\",\n",
    "    \"tam_Taml\",\n",
    "    \"quy_Latn\"\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T12:31:54.608418Z",
     "start_time": "2024-03-17T12:31:54.600433Z"
    }
   },
   "id": "4415667a44568410",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/reni/.cache/huggingface/modules/datasets_modules/datasets/facebook--flores/2a1174c8c4991ca09a9cb5b9a367cb2e049b073852cb4097456164d4612391ef (last modified on Tue Mar 12 01:26:11 2024) since it couldn't be found locally at facebook/flores, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/reni/.cache/huggingface/modules/datasets_modules/datasets/facebook--flores/2a1174c8c4991ca09a9cb5b9a367cb2e049b073852cb4097456164d4612391ef (last modified on Tue Mar 12 01:26:11 2024) since it couldn't be found locally at facebook/flores, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/reni/.cache/huggingface/modules/datasets_modules/datasets/facebook--flores/2a1174c8c4991ca09a9cb5b9a367cb2e049b073852cb4097456164d4612391ef (last modified on Tue Mar 12 01:26:11 2024) since it couldn't be found locally at facebook/flores, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/reni/.cache/huggingface/modules/datasets_modules/datasets/facebook--flores/2a1174c8c4991ca09a9cb5b9a367cb2e049b073852cb4097456164d4612391ef (last modified on Tue Mar 12 01:26:11 2024) since it couldn't be found locally at facebook/flores, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/reni/.cache/huggingface/modules/datasets_modules/datasets/facebook--flores/2a1174c8c4991ca09a9cb5b9a367cb2e049b073852cb4097456164d4612391ef (last modified on Tue Mar 12 01:26:11 2024) since it couldn't be found locally at facebook/flores, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/reni/.cache/huggingface/modules/datasets_modules/datasets/facebook--flores/2a1174c8c4991ca09a9cb5b9a367cb2e049b073852cb4097456164d4612391ef (last modified on Tue Mar 12 01:26:11 2024) since it couldn't be found locally at facebook/flores, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/reni/.cache/huggingface/modules/datasets_modules/datasets/facebook--flores/2a1174c8c4991ca09a9cb5b9a367cb2e049b073852cb4097456164d4612391ef (last modified on Tue Mar 12 01:26:11 2024) since it couldn't be found locally at facebook/flores, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/reni/.cache/huggingface/modules/datasets_modules/datasets/facebook--flores/2a1174c8c4991ca09a9cb5b9a367cb2e049b073852cb4097456164d4612391ef (last modified on Tue Mar 12 01:26:11 2024) since it couldn't be found locally at facebook/flores, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "# load flores data for each language\n",
    "# TODO: your code goes here\n",
    "multilang_dataset = {}\n",
    "for language in LANGUAGES:\n",
    "    multilang_dataset[language] = load_dataset(DATA_SET_NAME, language, trust_remote_code=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T12:33:15.172621Z",
     "start_time": "2024-03-17T12:31:54.610554Z"
    }
   },
   "id": "acfdba3ce7ef37c9",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# tokenize the data\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# load a pre-trained tokenizer from the huggingface hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, device_map = 'cuda')\n",
    "\n",
    "# specify the tokenization function\n",
    "def tokenization(example):\n",
    "    return tokenizer(example['sentence'])\n",
    "\n",
    "# TODO: your code goes here\n",
    "tokenization(multilang_dataset[\"eng_Latn\"][\"dev\"])\n",
    "tokenized_multilang_dataset = {}\n",
    "for key, data in multilang_dataset.items():\n",
    "    tokenized_multilang_dataset[key] = data.map(tokenization, batched=True)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T12:33:27.441640Z",
     "start_time": "2024-03-17T12:33:15.174109Z"
    }
   },
   "id": "2bf04106b7d4ee6b",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for key, data in tokenized_multilang_dataset.items():\n",
    "    tokenized_multilang_dataset[key] = tokenized_multilang_dataset[key][\"dev\"].remove_columns([\"id\", \"URL\", \"domain\", \"topic\", \"has_image\", \"has_hyperlink\", \"sentence\"])\n",
    "    tokenized_multilang_dataset[key].set_format(\"torch\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T12:33:27.457525Z",
     "start_time": "2024-03-17T12:33:27.443048Z"
    }
   },
   "id": "a432037608325b2c",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'eng_Latn': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n }),\n 'spa_Latn': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n }),\n 'ita_Latn': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n }),\n 'deu_Latn': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n }),\n 'arb_Arab': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n }),\n 'tel_Telu': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n }),\n 'tam_Taml': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n }),\n 'quy_Latn': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n })}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_multilang_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T12:33:27.462818Z",
     "start_time": "2024-03-17T12:33:27.459138Z"
    }
   },
   "id": "5587c11799e17e5e",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T12:33:27.471274Z",
     "start_time": "2024-03-17T12:33:27.464214Z"
    }
   },
   "id": "e9a7b829132c2b35",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "# iA3 model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ade785657554ae1c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "\n",
    "def list_attributes(obj):\n",
    "    attrs = [attr for attr in dir(obj) if not attr.startswith('__') and not callable(getattr(obj, attr))]\n",
    "    return attrs\n",
    "\n",
    "class IA3Linear(nn.Module):\n",
    "    def __init__(self, linear_layer):\n",
    "        super().__init__()\n",
    "        self.in_features = linear_layer.in_features\n",
    "        self.out_features = linear_layer.out_features\n",
    "        self.weight = linear_layer.weight\n",
    "        self.bias = linear_layer.bias\n",
    "        self.multi_lora_a = nn.Parameter(torch.ones(1, linear_layer.in_features))\n",
    "        self.multi_lora_b = nn.Parameter(torch.ones(linear_layer.out_features, 1))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        if self.multi_lora_a.requires_grad:\n",
    "            hidden = F.linear((input * self.multi_lora_a.flatten()), self.weight, self.bias)\n",
    "        else:\n",
    "            hidden = F.linear(input, self.weight, self.bias)\n",
    "        if self.multi_lora_b.requires_grad:\n",
    "            hidden = hidden * self.multi_lora_b.flatten()\n",
    "        return hidden\n",
    "    \n",
    "    def extra_repr(self):\n",
    "        return \"in_features={}, out_features={}, bias={}\".format(\n",
    "            self.in_features, self.out_features, self.bias is not None\n",
    "        )\n",
    "\n",
    "def modify_with_ia3(transformer, config):\n",
    "    for m_name, module in dict(transformer.named_modules()).items():\n",
    "        if re.fullmatch(config.lora_modules, m_name):\n",
    "            if re.fullmatch(\".*fc.*\", m_name):\n",
    "                assert isinstance(\n",
    "                    module, nn.Linear\n",
    "                ), f\"iA3 can only be applied to torch.nn.Linear, but {module} is {type(module)}.\"\n",
    "                setattr(\n",
    "                    transformer,\n",
    "                    m_name,\n",
    "                    IA3Linear(module),\n",
    "                )\n",
    "                # print(m_name, getattr(transformer, m_name))\n",
    "            else:\n",
    "                for c_name, layer in dict(module.named_children()).items():\n",
    "                    if re.fullmatch(config.lora_layers, c_name):\n",
    "                        assert isinstance(\n",
    "                            layer, nn.Linear\n",
    "                        ), f\"iA3 can only be applied to torch.nn.Linear, but {layer} is {type(layer)}.\"\n",
    "                        setattr(\n",
    "                            module,\n",
    "                            c_name,\n",
    "                            IA3Linear(layer),\n",
    "                        )\n",
    "                        # print(c_name, getattr(module, c_name))\n",
    "    return transformer\n",
    "\n",
    "def modify_transformer(transformer, config):\n",
    "    transformer = modify_with_ia3(transformer, config)\n",
    "    return transformer\n",
    "\n",
    "def get_transformer(model, config):\n",
    "    # print(model)\n",
    "    model = modify_transformer(model, config)\n",
    "    # print(model)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T12:33:27.481543Z",
     "start_time": "2024-03-17T12:33:27.472933Z"
    }
   },
   "id": "b23c10d5b705f6af",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self, trainable_param_names=\".*\", model_modifier=\"\", num_steps=300, lora_modules=\"none\", lora_layers=\"none\", origin_model=\"facebook/xglm-564M\"):\n",
    "        self.trainable_param_names = trainable_param_names\n",
    "        self.model_modifier = model_modifier\n",
    "        self.num_steps = num_steps\n",
    "        self.lora_modules = lora_modules\n",
    "        self.lora_layers = lora_layers\n",
    "        self.origin_model = origin_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T12:33:27.493071Z",
     "start_time": "2024-03-17T12:33:27.482763Z"
    }
   },
   "id": "f16eedf74b70c10c",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reni/miniconda3/envs/hws_ws23/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters in origin model : 564463616\n",
      "Total trainable parameters in iA3 model : 344064\n",
      "iA3 model params : 0.060954150143133407 % of the original model\n"
     ]
    }
   ],
   "source": [
    "config = Config(\n",
    "    # lora_modules=\".*SelfAttention|.*EncDecAttention|.*DenseReluDense\",\n",
    "    lora_modules=\".*fc.*|.*self_attn\",\n",
    "    lora_layers=\"k_proj|v_proj\",\n",
    "    trainable_param_names=\".*lora_b.*\",\n",
    "    model_modifier=\"lora\",\n",
    "    num_steps=1000,\n",
    "    origin_model=\"facebook/xglm-564M\"\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(config.origin_model)\n",
    "origin_model_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters in origin model : {origin_model_parameters}\")\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "model = get_transformer(model, config)\n",
    "\n",
    "model_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters in iA3 model : {model_params}\")\n",
    "\n",
    "print(f\"iA3 model params : {(model_params/origin_model_parameters)*100} % of the original model\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T12:33:48.656224Z",
     "start_time": "2024-03-17T12:33:27.494654Z"
    }
   },
   "id": "9078826b59d95d4f",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "182b5acde8e468b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"] = \"XGLM finetuning\"  # name your W&B project\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n",
    "os.environ[\"WANDB_WATCH\"]=\"all\"\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T12:33:48.660817Z",
     "start_time": "2024-03-17T12:33:48.657712Z"
    }
   },
   "id": "de8c0233b30b7d2e",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"xglm_ia3\",\n",
    "    evaluation_strategy = \"steps\",\n",
    "    eval_steps=200,\n",
    "    save_total_limit=4,\n",
    "    save_steps=200,\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    report_to=[\"wandb\"],\n",
    "    run_name=\"IA3_TWO_WIKI\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    metric_for_best_model=\"quy_Latn_loss\",\n",
    "    num_train_epochs=3,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets,\n",
    "    eval_dataset=tokenized_multilang_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T12:33:50.480531Z",
     "start_time": "2024-03-17T12:33:48.662131Z"
    }
   },
   "id": "d0abba06b313df73",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.3"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='201' max='1062' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 201/1062 01:30 < 06:31, 2.20 it/s, Epoch 0.56/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Eng Latn Loss</th>\n      <th>Spa Latn Loss</th>\n      <th>Ita Latn Loss</th>\n      <th>Deu Latn Loss</th>\n      <th>Arb Arab Loss</th>\n      <th>Tel Telu Loss</th>\n      <th>Tam Taml Loss</th>\n      <th>Quy Latn Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>5.507000</td>\n      <td>No log</td>\n      <td>5.251126</td>\n      <td>4.838367</td>\n      <td>4.871745</td>\n      <td>4.898452</td>\n      <td>4.941866</td>\n      <td>4.581558</td>\n      <td>4.382462</td>\n      <td>7.026469</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='401' max='1062' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 401/1062 06:00 < 09:57, 1.11 it/s, Epoch 1.13/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Eng Latn Loss</th>\n      <th>Spa Latn Loss</th>\n      <th>Ita Latn Loss</th>\n      <th>Deu Latn Loss</th>\n      <th>Arb Arab Loss</th>\n      <th>Tel Telu Loss</th>\n      <th>Tam Taml Loss</th>\n      <th>Quy Latn Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>5.507000</td>\n      <td>No log</td>\n      <td>5.251126</td>\n      <td>4.838367</td>\n      <td>4.871745</td>\n      <td>4.898452</td>\n      <td>4.941866</td>\n      <td>4.581558</td>\n      <td>4.382462</td>\n      <td>7.026469</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>5.323700</td>\n      <td>No log</td>\n      <td>5.247837</td>\n      <td>4.834729</td>\n      <td>4.868670</td>\n      <td>4.895500</td>\n      <td>4.940695</td>\n      <td>4.579723</td>\n      <td>4.380736</td>\n      <td>7.012404</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='601' max='1062' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 601/1062 10:28 < 08:03, 0.95 it/s, Epoch 1.69/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Eng Latn Loss</th>\n      <th>Spa Latn Loss</th>\n      <th>Ita Latn Loss</th>\n      <th>Deu Latn Loss</th>\n      <th>Arb Arab Loss</th>\n      <th>Tel Telu Loss</th>\n      <th>Tam Taml Loss</th>\n      <th>Quy Latn Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>5.507000</td>\n      <td>No log</td>\n      <td>5.251126</td>\n      <td>4.838367</td>\n      <td>4.871745</td>\n      <td>4.898452</td>\n      <td>4.941866</td>\n      <td>4.581558</td>\n      <td>4.382462</td>\n      <td>7.026469</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>5.323700</td>\n      <td>No log</td>\n      <td>5.247837</td>\n      <td>4.834729</td>\n      <td>4.868670</td>\n      <td>4.895500</td>\n      <td>4.940695</td>\n      <td>4.579723</td>\n      <td>4.380736</td>\n      <td>7.012404</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>5.628100</td>\n      <td>No log</td>\n      <td>5.245466</td>\n      <td>4.832100</td>\n      <td>4.866451</td>\n      <td>4.893385</td>\n      <td>4.939839</td>\n      <td>4.578383</td>\n      <td>4.379477</td>\n      <td>7.002104</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='801' max='1062' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 801/1062 15:05 < 04:55, 0.88 it/s, Epoch 2.26/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Eng Latn Loss</th>\n      <th>Spa Latn Loss</th>\n      <th>Ita Latn Loss</th>\n      <th>Deu Latn Loss</th>\n      <th>Arb Arab Loss</th>\n      <th>Tel Telu Loss</th>\n      <th>Tam Taml Loss</th>\n      <th>Quy Latn Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>5.507000</td>\n      <td>No log</td>\n      <td>5.251126</td>\n      <td>4.838367</td>\n      <td>4.871745</td>\n      <td>4.898452</td>\n      <td>4.941866</td>\n      <td>4.581558</td>\n      <td>4.382462</td>\n      <td>7.026469</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>5.323700</td>\n      <td>No log</td>\n      <td>5.247837</td>\n      <td>4.834729</td>\n      <td>4.868670</td>\n      <td>4.895500</td>\n      <td>4.940695</td>\n      <td>4.579723</td>\n      <td>4.380736</td>\n      <td>7.012404</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>5.628100</td>\n      <td>No log</td>\n      <td>5.245466</td>\n      <td>4.832100</td>\n      <td>4.866451</td>\n      <td>4.893385</td>\n      <td>4.939839</td>\n      <td>4.578383</td>\n      <td>4.379477</td>\n      <td>7.002104</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>5.789300</td>\n      <td>No log</td>\n      <td>5.244091</td>\n      <td>4.830554</td>\n      <td>4.865139</td>\n      <td>4.892136</td>\n      <td>4.939370</td>\n      <td>4.577617</td>\n      <td>4.378764</td>\n      <td>6.995991</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1001' max='1062' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1001/1062 19:41 < 01:12, 0.85 it/s, Epoch 2.82/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Eng Latn Loss</th>\n      <th>Spa Latn Loss</th>\n      <th>Ita Latn Loss</th>\n      <th>Deu Latn Loss</th>\n      <th>Arb Arab Loss</th>\n      <th>Tel Telu Loss</th>\n      <th>Tam Taml Loss</th>\n      <th>Quy Latn Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>5.507000</td>\n      <td>No log</td>\n      <td>5.251126</td>\n      <td>4.838367</td>\n      <td>4.871745</td>\n      <td>4.898452</td>\n      <td>4.941866</td>\n      <td>4.581558</td>\n      <td>4.382462</td>\n      <td>7.026469</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>5.323700</td>\n      <td>No log</td>\n      <td>5.247837</td>\n      <td>4.834729</td>\n      <td>4.868670</td>\n      <td>4.895500</td>\n      <td>4.940695</td>\n      <td>4.579723</td>\n      <td>4.380736</td>\n      <td>7.012404</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>5.628100</td>\n      <td>No log</td>\n      <td>5.245466</td>\n      <td>4.832100</td>\n      <td>4.866451</td>\n      <td>4.893385</td>\n      <td>4.939839</td>\n      <td>4.578383</td>\n      <td>4.379477</td>\n      <td>7.002104</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>5.789300</td>\n      <td>No log</td>\n      <td>5.244091</td>\n      <td>4.830554</td>\n      <td>4.865139</td>\n      <td>4.892136</td>\n      <td>4.939370</td>\n      <td>4.577617</td>\n      <td>4.378764</td>\n      <td>6.995991</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>5.615900</td>\n      <td>No log</td>\n      <td>5.243456</td>\n      <td>4.829858</td>\n      <td>4.864553</td>\n      <td>4.891571</td>\n      <td>4.939165</td>\n      <td>4.577302</td>\n      <td>4.378468</td>\n      <td>6.993324</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1063' max='1062' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1062/1062 23:15, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Eng Latn Loss</th>\n      <th>Spa Latn Loss</th>\n      <th>Ita Latn Loss</th>\n      <th>Deu Latn Loss</th>\n      <th>Arb Arab Loss</th>\n      <th>Tel Telu Loss</th>\n      <th>Tam Taml Loss</th>\n      <th>Quy Latn Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>5.507000</td>\n      <td>No log</td>\n      <td>5.251126</td>\n      <td>4.838367</td>\n      <td>4.871745</td>\n      <td>4.898452</td>\n      <td>4.941866</td>\n      <td>4.581558</td>\n      <td>4.382462</td>\n      <td>7.026469</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>5.323700</td>\n      <td>No log</td>\n      <td>5.247837</td>\n      <td>4.834729</td>\n      <td>4.868670</td>\n      <td>4.895500</td>\n      <td>4.940695</td>\n      <td>4.579723</td>\n      <td>4.380736</td>\n      <td>7.012404</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>5.628100</td>\n      <td>No log</td>\n      <td>5.245466</td>\n      <td>4.832100</td>\n      <td>4.866451</td>\n      <td>4.893385</td>\n      <td>4.939839</td>\n      <td>4.578383</td>\n      <td>4.379477</td>\n      <td>7.002104</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>5.789300</td>\n      <td>No log</td>\n      <td>5.244091</td>\n      <td>4.830554</td>\n      <td>4.865139</td>\n      <td>4.892136</td>\n      <td>4.939370</td>\n      <td>4.577617</td>\n      <td>4.378764</td>\n      <td>6.995991</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>5.615900</td>\n      <td>No log</td>\n      <td>5.243456</td>\n      <td>4.829858</td>\n      <td>4.864553</td>\n      <td>4.891571</td>\n      <td>4.939165</td>\n      <td>4.577302</td>\n      <td>4.378468</td>\n      <td>6.993324</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1062' max='1062' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1062/1062 23:35, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Eng Latn Loss</th>\n      <th>Spa Latn Loss</th>\n      <th>Ita Latn Loss</th>\n      <th>Deu Latn Loss</th>\n      <th>Arb Arab Loss</th>\n      <th>Tel Telu Loss</th>\n      <th>Tam Taml Loss</th>\n      <th>Quy Latn Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>5.507000</td>\n      <td>No log</td>\n      <td>5.251126</td>\n      <td>4.838367</td>\n      <td>4.871745</td>\n      <td>4.898452</td>\n      <td>4.941866</td>\n      <td>4.581558</td>\n      <td>4.382462</td>\n      <td>7.026469</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>5.323700</td>\n      <td>No log</td>\n      <td>5.247837</td>\n      <td>4.834729</td>\n      <td>4.868670</td>\n      <td>4.895500</td>\n      <td>4.940695</td>\n      <td>4.579723</td>\n      <td>4.380736</td>\n      <td>7.012404</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>5.628100</td>\n      <td>No log</td>\n      <td>5.245466</td>\n      <td>4.832100</td>\n      <td>4.866451</td>\n      <td>4.893385</td>\n      <td>4.939839</td>\n      <td>4.578383</td>\n      <td>4.379477</td>\n      <td>7.002104</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>5.789300</td>\n      <td>No log</td>\n      <td>5.244091</td>\n      <td>4.830554</td>\n      <td>4.865139</td>\n      <td>4.892136</td>\n      <td>4.939370</td>\n      <td>4.577617</td>\n      <td>4.378764</td>\n      <td>6.995991</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>5.615900</td>\n      <td>No log</td>\n      <td>5.243456</td>\n      <td>4.829858</td>\n      <td>4.864553</td>\n      <td>4.891571</td>\n      <td>4.939165</td>\n      <td>4.577302</td>\n      <td>4.378468</td>\n      <td>6.993324</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ade158a026d34c67b74306078c35639d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/arb_Arab_loss</td><td>âââââ</td></tr><tr><td>eval/arb_Arab_runtime</td><td>âââââ</td></tr><tr><td>eval/arb_Arab_samples_per_second</td><td>âââââ</td></tr><tr><td>eval/arb_Arab_steps_per_second</td><td>âââââ</td></tr><tr><td>eval/deu_Latn_loss</td><td>âââââ</td></tr><tr><td>eval/deu_Latn_runtime</td><td>âââââ</td></tr><tr><td>eval/deu_Latn_samples_per_second</td><td>âââââ</td></tr><tr><td>eval/deu_Latn_steps_per_second</td><td>âââââ</td></tr><tr><td>eval/eng_Latn_loss</td><td>âââââ</td></tr><tr><td>eval/eng_Latn_runtime</td><td>âââââ</td></tr><tr><td>eval/eng_Latn_samples_per_second</td><td>âââââ</td></tr><tr><td>eval/eng_Latn_steps_per_second</td><td>âââââ</td></tr><tr><td>eval/ita_Latn_loss</td><td>âââââ</td></tr><tr><td>eval/ita_Latn_runtime</td><td>âââââ</td></tr><tr><td>eval/ita_Latn_samples_per_second</td><td>âââââ</td></tr><tr><td>eval/ita_Latn_steps_per_second</td><td>âââââ</td></tr><tr><td>eval/quy_Latn_loss</td><td>âââââ</td></tr><tr><td>eval/quy_Latn_runtime</td><td>âââââ</td></tr><tr><td>eval/quy_Latn_samples_per_second</td><td>âââââ</td></tr><tr><td>eval/quy_Latn_steps_per_second</td><td>âââââ</td></tr><tr><td>eval/spa_Latn_loss</td><td>âââââ</td></tr><tr><td>eval/spa_Latn_runtime</td><td>âââââ</td></tr><tr><td>eval/spa_Latn_samples_per_second</td><td>âââââ</td></tr><tr><td>eval/spa_Latn_steps_per_second</td><td>âââââ</td></tr><tr><td>eval/tam_Taml_loss</td><td>âââââ</td></tr><tr><td>eval/tam_Taml_runtime</td><td>âââââ</td></tr><tr><td>eval/tam_Taml_samples_per_second</td><td>âââââ</td></tr><tr><td>eval/tam_Taml_steps_per_second</td><td>âââââ</td></tr><tr><td>eval/tel_Telu_loss</td><td>âââââ</td></tr><tr><td>eval/tel_Telu_runtime</td><td>âââââ</td></tr><tr><td>eval/tel_Telu_samples_per_second</td><td>âââââ</td></tr><tr><td>eval/tel_Telu_steps_per_second</td><td>âââââ</td></tr><tr><td>train/epoch</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>train/global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>train/grad_norm</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>train/learning_rate</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>train/loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>train/total_flos</td><td>â</td></tr><tr><td>train/train_loss</td><td>â</td></tr><tr><td>train/train_runtime</td><td>â</td></tr><tr><td>train/train_samples_per_second</td><td>â</td></tr><tr><td>train/train_steps_per_second</td><td>â</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/arb_Arab_loss</td><td>4.93917</td></tr><tr><td>eval/arb_Arab_runtime</td><td>18.5759</td></tr><tr><td>eval/arb_Arab_samples_per_second</td><td>53.672</td></tr><tr><td>eval/arb_Arab_steps_per_second</td><td>6.729</td></tr><tr><td>eval/deu_Latn_loss</td><td>4.89157</td></tr><tr><td>eval/deu_Latn_runtime</td><td>21.0577</td></tr><tr><td>eval/deu_Latn_samples_per_second</td><td>47.346</td></tr><tr><td>eval/deu_Latn_steps_per_second</td><td>5.936</td></tr><tr><td>eval/eng_Latn_loss</td><td>5.24346</td></tr><tr><td>eval/eng_Latn_runtime</td><td>16.3028</td></tr><tr><td>eval/eng_Latn_samples_per_second</td><td>61.155</td></tr><tr><td>eval/eng_Latn_steps_per_second</td><td>7.667</td></tr><tr><td>eval/ita_Latn_loss</td><td>4.86455</td></tr><tr><td>eval/ita_Latn_runtime</td><td>17.9134</td></tr><tr><td>eval/ita_Latn_samples_per_second</td><td>55.657</td></tr><tr><td>eval/ita_Latn_steps_per_second</td><td>6.978</td></tr><tr><td>eval/quy_Latn_loss</td><td>6.99332</td></tr><tr><td>eval/quy_Latn_runtime</td><td>22.9076</td></tr><tr><td>eval/quy_Latn_samples_per_second</td><td>43.523</td></tr><tr><td>eval/quy_Latn_steps_per_second</td><td>5.457</td></tr><tr><td>eval/spa_Latn_loss</td><td>4.82986</td></tr><tr><td>eval/spa_Latn_runtime</td><td>17.3291</td></tr><tr><td>eval/spa_Latn_samples_per_second</td><td>57.533</td></tr><tr><td>eval/spa_Latn_steps_per_second</td><td>7.213</td></tr><tr><td>eval/tam_Taml_loss</td><td>4.37847</td></tr><tr><td>eval/tam_Taml_runtime</td><td>20.6859</td></tr><tr><td>eval/tam_Taml_samples_per_second</td><td>48.197</td></tr><tr><td>eval/tam_Taml_steps_per_second</td><td>6.043</td></tr><tr><td>eval/tel_Telu_loss</td><td>4.5773</td></tr><tr><td>eval/tel_Telu_runtime</td><td>21.2245</td></tr><tr><td>eval/tel_Telu_samples_per_second</td><td>46.974</td></tr><tr><td>eval/tel_Telu_steps_per_second</td><td>5.889</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>1062</td></tr><tr><td>train/grad_norm</td><td>0.23401</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>5.5378</td></tr><tr><td>train/total_flos</td><td>1974107949760512.0</td></tr><tr><td>train/train_loss</td><td>5.40266</td></tr><tr><td>train/train_runtime</td><td>1406.5692</td></tr><tr><td>train/train_samples_per_second</td><td>6.038</td></tr><tr><td>train/train_steps_per_second</td><td>0.755</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "You can sync this run to the cloud by running:<br/><code>wandb sync /home/reni/Documents/hws_ws23/nnti_project/notebooks/wandb/offline-run-20240317_133351-nl4lq9wg<code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/offline-run-20240317_133351-nl4lq9wg/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training time : 1421.5935325622559 sec.\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "st = time.time()\n",
    "trainer.train()\n",
    "et = time.time()\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "print(f\"total training time : {(et - st)} sec.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T12:57:33.343776Z",
     "start_time": "2024-03-17T12:33:50.482094Z"
    }
   },
   "id": "411fa20fb3ce6b6e",
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
