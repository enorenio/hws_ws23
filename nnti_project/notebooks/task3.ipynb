{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:10:41.287260Z",
     "start_time": "2024-03-16T00:10:41.282714Z"
    }
   },
   "outputs": [],
   "source": [
    "packages_to_install = {\n",
    "    \"ipywidgets\": \"ipywidgets\",\n",
    "    \"numpy\": \"numpy=1.24.0\",\n",
    "    \"torch\": \"torch\",\n",
    "    \"matplotlib\": \"matplotlib\",\n",
    "    \"sentencepiece\": \"sentencepiece\",\n",
    "    \"protobuf\": \"protobuf\",\n",
    "    \"datasets\": \"datasets\",\n",
    "    \"transformers\": \"transformers\",\n",
    "    \"diffusers\": \"diffusers\",\n",
    "    \"peft\": \"peft\",\n",
    "    \"h5py\": \"h5py\",\n",
    "    \"scikit-learn\": \"scikit-learn\",\n",
    "    \"scipy\": \"scipy\",\n",
    "    \"wandb\": \"wandb\",\n",
    "    \"mwparserfromhell\": \"mwparserfromhell\",\n",
    "    \"apache_beam\": \"apache_beam\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipywidgets is already installed.\n",
      "numpy is already installed.\n",
      "torch is already installed.\n",
      "matplotlib is already installed.\n",
      "sentencepiece is already installed.\n",
      "protobuf is not installed. Installing it now...\n",
      "Collecting package metadata (current_repodata.json): - WARNING conda.models.version:get_matcher(556): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.*, but conda is ignoring the .* and treating it as 1.7.1\r\n",
      "done\r\n",
      "Solving environment: done\r\n",
      "\r\n",
      "\r\n",
      "==> WARNING: A newer version of conda exists. <==\r\n",
      "  current version: 23.7.4\r\n",
      "  latest version: 24.1.2\r\n",
      "\r\n",
      "Please update conda by running\r\n",
      "\r\n",
      "    $ conda update -n base -c conda-forge conda\r\n",
      "\r\n",
      "Or to minimize the number of packages updated during conda update use\r\n",
      "\r\n",
      "     conda install conda=24.1.2\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "# All requested packages already installed.\r\n",
      "\r\n",
      "datasets is already installed.\n",
      "transformers is already installed.\n",
      "diffusers is already installed.\n",
      "peft is already installed.\n",
      "h5py is already installed.\n",
      "scikit-learn is not installed. Installing it now...\n",
      "Collecting package metadata (current_repodata.json): | WARNING conda.models.version:get_matcher(556): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.*, but conda is ignoring the .* and treating it as 1.7.1\r\n",
      "done\r\n",
      "Solving environment: done\r\n",
      "\r\n",
      "\r\n",
      "==> WARNING: A newer version of conda exists. <==\r\n",
      "  current version: 23.7.4\r\n",
      "  latest version: 24.1.2\r\n",
      "\r\n",
      "Please update conda by running\r\n",
      "\r\n",
      "    $ conda update -n base -c conda-forge conda\r\n",
      "\r\n",
      "Or to minimize the number of packages updated during conda update use\r\n",
      "\r\n",
      "     conda install conda=24.1.2\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "# All requested packages already installed.\r\n",
      "\r\n",
      "scipy is already installed.\n",
      "wandb is already installed.\n",
      "mwparserfromhell is not installed. Installing it now...\n",
      "Collecting package metadata (current_repodata.json): - WARNING conda.models.version:get_matcher(556): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.*, but conda is ignoring the .* and treating it as 1.7.1\r\n",
      "done\r\n",
      "Solving environment: done\r\n",
      "\r\n",
      "\r\n",
      "==> WARNING: A newer version of conda exists. <==\r\n",
      "  current version: 23.7.4\r\n",
      "  latest version: 24.1.2\r\n",
      "\r\n",
      "Please update conda by running\r\n",
      "\r\n",
      "    $ conda update -n base -c conda-forge conda\r\n",
      "\r\n",
      "Or to minimize the number of packages updated during conda update use\r\n",
      "\r\n",
      "     conda install conda=24.1.2\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "## Package Plan ##\r\n",
      "\r\n",
      "  environment location: /home/reni/miniconda3/envs/hws_ws23\r\n",
      "\r\n",
      "  added / updated specs:\r\n",
      "    - mwparserfromhell\r\n",
      "\r\n",
      "\r\n",
      "The following packages will be downloaded:\r\n",
      "\r\n",
      "    package                    |            build\r\n",
      "    ---------------------------|-----------------\r\n",
      "    mwparserfromhell-0.6.5     |  py310h2372a71_0         117 KB  conda-forge\r\n",
      "    ------------------------------------------------------------\r\n",
      "                                           Total:         117 KB\r\n",
      "\r\n",
      "The following NEW packages will be INSTALLED:\r\n",
      "\r\n",
      "  mwparserfromhell   conda-forge/linux-64::mwparserfromhell-0.6.5-py310h2372a71_0 \r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Downloading and Extracting Packages\r\n",
      "                                                                                \r\n",
      "Preparing transaction: done\r\n",
      "Verifying transaction: done\r\n",
      "Executing transaction: done\r\n",
      "apache_beam is not installed. Installing it now...\n",
      "Collecting package metadata (current_repodata.json): \\ WARNING conda.models.version:get_matcher(556): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.*, but conda is ignoring the .* and treating it as 1.7.1\r\n",
      "done\r\n",
      "Solving environment: unsuccessful initial attempt using frozen solve. Retrying with flexible solve.\r\n",
      "Collecting package metadata (repodata.json): - WARNING conda.models.version:get_matcher(556): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.6.0.*, but conda is ignoring the .* and treating it as 1.6.0\r\n",
      "WARNING conda.models.version:get_matcher(556): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.9.0.*, but conda is ignoring the .* and treating it as 1.9.0\r\n",
      "WARNING conda.models.version:get_matcher(556): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.8.0.*, but conda is ignoring the .* and treating it as 1.8.0\r\n",
      "done\r\n",
      "Solving environment: unsuccessful initial attempt using frozen solve. Retrying with flexible solve.\r\n",
      "\r\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\r\n",
      "\r\n",
      "  - apache_beam\r\n",
      "\r\n",
      "Current channels:\r\n",
      "\r\n",
      "  - https://conda.anaconda.org/conda-forge/linux-64\r\n",
      "  - https://conda.anaconda.org/conda-forge/noarch\r\n",
      "  - https://repo.anaconda.com/pkgs/main/linux-64\r\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\r\n",
      "  - https://repo.anaconda.com/pkgs/r/linux-64\r\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\r\n",
      "\r\n",
      "To search for alternate channels that may provide the conda package you're\r\n",
      "looking for, navigate to\r\n",
      "\r\n",
      "    https://anaconda.org\r\n",
      "\r\n",
      "and use the search bar at the top of the page.\r\n",
      "\r\n",
      "\r\n",
      "CPU times: user 5.68 s, sys: 1.57 s, total: 7.25 s\n",
      "Wall time: 5min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import importlib\n",
    "\n",
    "for package_name, install_command in packages_to_install.items():\n",
    "    try:\n",
    "        importlib.import_module(package_name)\n",
    "        print(f\"{package_name} is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"{package_name} is not installed. Installing it now...\")\n",
    "        !conda install -y {install_command}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:15:46.621093Z",
     "start_time": "2024-03-16T00:10:41.427623Z"
    }
   },
   "id": "62f543449a0b33f2",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:15:46.628874Z",
     "start_time": "2024-03-16T00:15:46.623904Z"
    }
   },
   "id": "aaf9b7b5eed49543",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# from datasets import load_dataset, load_dataset_builder, get_dataset_split_names, get_dataset_config_names\n",
    "from transformers import XGLMTokenizer, XGLMTokenizerFast, XGLMForCausalLM, AutoModelForCausalLM, AutoTokenizer, GenerationConfig, DataCollatorWithPadding"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:15:46.640695Z",
     "start_time": "2024-03-16T00:15:46.631094Z"
    }
   },
   "id": "8ce764012d7341a5",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build Dataset\n",
    "\n",
    "## Training Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5decc93e4e11cfa"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "833ab4ab33634e6185448ec90670816a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting content from /home/reni/.cache/huggingface/datasets/downloads/d7201af134283fb091b2110c88fe778c686b0d9c49f1d3a573d40a87cce26d13\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "qu_data = load_dataset(\"wikipedia\", language=\"qu\", date=\"20240301\", trust_remote_code=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:17:55.041615Z",
     "start_time": "2024-03-16T00:15:46.644015Z"
    }
   },
   "id": "5d7df955695099a6",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Filter:   0%|          | 0/24240 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1cc80891d12846a090a4af78007e20cb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_dataset = qu_data.filter(lambda example: len(example['text']) <= 2048)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:17:55.208154Z",
     "start_time": "2024-03-16T00:17:55.043587Z"
    }
   },
   "id": "3764ab4ca1d44a2d",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "shuffled_dataset = filtered_dataset.shuffle(seed=42)\n",
    "filtered_dataset = shuffled_dataset[\"train\"].select(range(2500))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:17:55.225914Z",
     "start_time": "2024-03-16T00:17:55.209674Z"
    }
   },
   "id": "e2e14b27a5a4ace",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map (num_proc=4):   0%|          | 0/2500 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d39cc7104322488397fc3118fd7ac416"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = \"facebook/xglm-564M\" # specify model name\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, device_map = 'cuda')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"])\n",
    "# tokenized_qu_data = filtered_dataset.map(tokenize_function, batched=True, num_proc=4, remove_columns=filtered_dataset[\"train\"].column_names)\n",
    "tokenized_qu_data = filtered_dataset.map(tokenize_function, batched=True, num_proc=4, remove_columns=filtered_dataset.column_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:17:57.857358Z",
     "start_time": "2024-03-16T00:17:55.227724Z"
    }
   },
   "id": "bb9d3cf9a42705c3",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "block_size = 128\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:17:57.864926Z",
     "start_time": "2024-03-16T00:17:57.859624Z"
    }
   },
   "id": "63e4d0239df7aca9",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map (num_proc=4):   0%|          | 0/2500 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e73df0bbf08843f3a2a1fa0173b85384"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_datasets = tokenized_qu_data.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:17:58.277648Z",
     "start_time": "2024-03-16T00:17:57.867313Z"
    }
   },
   "id": "a2429d9429c8c326",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\"m) 153 km Yunkay (2.500 m) 163 km Qaras (2.290 m) 205 km Wallanka (1.820 m) 215 km Yuramarka (1.420 m) 343 km Santa (20 m) Kaypipas qhaway Patu Wayq'u Waylas Pukyukuna Instituto Nacional GeogrÃ¡fico Mayu (Piruw) Mayu (Anqash suyu) Mayu (Qispi kay suyu) Rikuway pruwinsya Santa pruwinsya Waras pruwinsya Waylas pruwinsya</s> Nonato Rufino Chuquimamani Valer sutiyuq runaqa (1946 watapi pa\""
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])\n",
    "tokenizer.decode(lm_datasets[1][\"input_ids\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:17:58.288213Z",
     "start_time": "2024-03-16T00:17:58.281121Z"
    }
   },
   "id": "8cb56126472e10aa",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validation Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb774566d7209f01"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "DATA_SET_NAME = \"facebook/flores\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:17:58.297178Z",
     "start_time": "2024-03-16T00:17:58.289948Z"
    }
   },
   "id": "9f07a8a90c3016de",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# specify languages\n",
    "LANGUAGES = [\n",
    "    \"eng_Latn\",\n",
    "    \"spa_Latn\",\n",
    "    \"ita_Latn\",\n",
    "    \"deu_Latn\",\n",
    "    \"arb_Arab\",\n",
    "    \"tel_Telu\",\n",
    "    \"tam_Taml\",\n",
    "    \"quy_Latn\"\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:17:58.307263Z",
     "start_time": "2024-03-16T00:17:58.298849Z"
    }
   },
   "id": "ec5d9a86abdf3ec7",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reni/miniconda3/envs/hws_ws23/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for facebook/flores contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/facebook/flores\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load flores data for each language\n",
    "# TODO: your code goes here\n",
    "multilang_dataset = {}\n",
    "for language in LANGUAGES:\n",
    "    multilang_dataset[language] = load_dataset(DATA_SET_NAME, language)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:18:15.122506Z",
     "start_time": "2024-03-16T00:17:58.309237Z"
    }
   },
   "id": "42d9e1ef730c40b3",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/997 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf80a872b7ff435d9bf2ec4b43a894ef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1012 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7fb77fd757ba43fa98aedea482601102"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/997 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72381ba6cfee4b4e98d9284ee95cb0c5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1012 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d3955b1cf13d456aad70c5ddd244705e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/997 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "514b5a2bcada428c93ada9800e7ae511"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1012 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a58073af64a6489dae5a4f5201764c2c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/997 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f7ec48c792649699c88d63ecc2d84c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1012 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ae5ed934e0c40989c515c4bd2b5f1c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/997 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c055860037d34332ab8deeee8df3d847"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1012 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "07c63b15c1294f1cb150ac1e106989ca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/997 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aac3a7f20db34b1d82e76616b9308232"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1012 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5ee898d37ea4d088986f0afd78d2cf8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/997 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d913ada1915b402e88e60cafc33265ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1012 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "76ecfe3d2e1c4c2cb42b6a9ed230f8ca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/997 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e045d6b496c9457e8380c67c533c59fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1012 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2130bd17bd104b37a733d9ee7e565884"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize the data\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# load a pre-trained tokenizer from the huggingface hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, device_map = 'cuda')\n",
    "\n",
    "# gpt2 does not have a padding token, so we have to add it manually\n",
    "if MODEL_NAME == \"gpt2\":\n",
    "    tokenizer.add_special_tokens({'pad_token': tokenizer.unk_token})\n",
    "\n",
    "# specify the tokenization function\n",
    "def tokenization(example):\n",
    "    return tokenizer(example['sentence'])\n",
    "\n",
    "# TODO: your code goes here\n",
    "tokenization(multilang_dataset[\"eng_Latn\"][\"dev\"])\n",
    "tokenized_multilang_dataset = {}\n",
    "for key, data in multilang_dataset.items():\n",
    "    tokenized_multilang_dataset[key] = data.map(tokenization, batched=True)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:18:19.521002Z",
     "start_time": "2024-03-16T00:18:15.124143Z"
    }
   },
   "id": "d69d223eca7b1872",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for key, data in tokenized_multilang_dataset.items():\n",
    "    tokenized_multilang_dataset[key] = tokenized_multilang_dataset[key][\"dev\"].remove_columns([\"id\", \"URL\", \"domain\", \"topic\", \"has_image\", \"has_hyperlink\", \"sentence\"])\n",
    "    tokenized_multilang_dataset[key].set_format(\"torch\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:18:19.533072Z",
     "start_time": "2024-03-16T00:18:19.522372Z"
    }
   },
   "id": "9239e764706089de",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'eng_Latn': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n }),\n 'spa_Latn': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n }),\n 'ita_Latn': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n }),\n 'deu_Latn': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n }),\n 'arb_Arab': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n }),\n 'tel_Telu': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n }),\n 'tam_Taml': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n }),\n 'quy_Latn': Dataset({\n     features: ['input_ids', 'attention_mask'],\n     num_rows: 997\n })}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_multilang_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:18:19.538054Z",
     "start_time": "2024-03-16T00:18:19.534499Z"
    }
   },
   "id": "9aa1dd114ca62bea",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # construct a pytorch data loader for each dataset\n",
    "# BATCH_SIZE = 2 # for testing purposes, we start with a batch size of 2. You can change this later.\n",
    "\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# # random_test_dataloader = DataLoader(random_test_dataset, batch_size=1, shuffle=False)\n",
    "# # for i,data in random_test_dataloader:\n",
    "# #     print(i)\n",
    "\n",
    "# def make_dataloaders(multilang_dataset):\n",
    "#     dataloaders_dict = {}\n",
    "#     for key, dataset_dict in multilang_dataset.items():\n",
    "#         dataloaders_dict[key] = {\"dev\":DataLoader(multilang_dataset[key][\"dev\"], batch_size=BATCH_SIZE, collate_fn=data_collator, shuffle = True),\n",
    "#                                  \"devtest\": DataLoader(multilang_dataset[key][\"devtest\"], batch_size=BATCH_SIZE, collate_fn=data_collator, shuffle = True)}\n",
    "#     return dataloaders_dict\n",
    "\n",
    "# dataloaders_dict = make_dataloaders(tokenized_multilang_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:18:19.545010Z",
     "start_time": "2024-03-16T00:18:19.539374Z"
    }
   },
   "id": "90c4bda2c0489c81",
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af0069e162d925fb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:18:19.553070Z",
     "start_time": "2024-03-16T00:18:19.546655Z"
    }
   },
   "id": "9e2f2161aaa24326",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load pre-trained model from the huggingface hub\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map = 'cuda') # HERE , device_map = 'cuda'\n",
    "# model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# put the model into evaluation mode\n",
    "# TODO: your code goes here\n",
    "# model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:19:22.018374Z",
     "start_time": "2024-03-16T00:19:19.480321Z"
    }
   },
   "id": "2a2083942a185807",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "XGLMForCausalLM(\n  (model): XGLMModel(\n    (embed_tokens): Embedding(256008, 1024, padding_idx=1)\n    (embed_positions): XGLMSinusoidalPositionalEmbedding()\n    (layers): ModuleList(\n      (0-23): 24 x XGLMDecoderLayer(\n        (self_attn): XGLMAttention(\n          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        )\n        (activation_fn): GELUActivation()\n        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=1024, out_features=256008, bias=False)\n)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:19:22.026943Z",
     "start_time": "2024-03-16T00:19:22.020296Z"
    }
   },
   "id": "f0a08d6622443770",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"] = \"XGLM finetuning\"  # name your W&B project\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n",
    "os.environ[\"WANDB_WATCH\"]=\"all\"\n",
    "# os.environ[\"WANDB_SILENT\"]=\"true\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:19:22.040617Z",
     "start_time": "2024-03-16T00:19:22.028662Z"
    }
   },
   "id": "94eeefe1db14d62d",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"finetuned-full\",\n",
    "    evaluation_strategy = \"steps\",\n",
    "    eval_steps=200,\n",
    "    save_total_limit=4,\n",
    "    save_steps=200,\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"FullFT_1\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    metric_for_best_model=\"quy_Latn_loss\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:19:22.053236Z",
     "start_time": "2024-03-16T00:19:22.042798Z"
    }
   },
   "id": "5f945cd895c91a54",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=lm_datasets[\"train\"],\n",
    "#     eval_dataset=tokenized_multilang_dataset,\n",
    "#     data_collator=data_collator,\n",
    "#     tokenizer=tokenizer\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:19:22.066670Z",
     "start_time": "2024-03-16T00:19:22.054676Z"
    }
   },
   "id": "6846121ce8fbef5c",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets,\n",
    "    eval_dataset=tokenized_multilang_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T00:19:22.084669Z",
     "start_time": "2024-03-16T00:19:22.068523Z"
    }
   },
   "id": "8e3adecc7a1b4a69",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='201' max='1062' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 201/1062 46:16 < 3:20:13, 0.07 it/s, Epoch 0.56/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Eng Latn Loss</th>\n      <th>Spa Latn Loss</th>\n      <th>Ita Latn Loss</th>\n      <th>Deu Latn Loss</th>\n      <th>Arb Arab Loss</th>\n      <th>Tel Telu Loss</th>\n      <th>Tam Taml Loss</th>\n      <th>Quy Latn Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>3.877200</td>\n      <td>No log</td>\n      <td>5.139099</td>\n      <td>4.662704</td>\n      <td>4.814327</td>\n      <td>4.831931</td>\n      <td>4.995979</td>\n      <td>4.636125</td>\n      <td>4.420599</td>\n      <td>6.300550</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='401' max='1062' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 401/1062 2:15:00 < 3:43:39, 0.05 it/s, Epoch 1.13/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Eng Latn Loss</th>\n      <th>Spa Latn Loss</th>\n      <th>Ita Latn Loss</th>\n      <th>Deu Latn Loss</th>\n      <th>Arb Arab Loss</th>\n      <th>Tel Telu Loss</th>\n      <th>Tam Taml Loss</th>\n      <th>Quy Latn Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>3.877200</td>\n      <td>No log</td>\n      <td>5.139099</td>\n      <td>4.662704</td>\n      <td>4.814327</td>\n      <td>4.831931</td>\n      <td>4.995979</td>\n      <td>4.636125</td>\n      <td>4.420599</td>\n      <td>6.300550</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>3.196600</td>\n      <td>No log</td>\n      <td>5.206576</td>\n      <td>4.687542</td>\n      <td>4.879029</td>\n      <td>4.879976</td>\n      <td>5.010794</td>\n      <td>4.662020</td>\n      <td>4.423977</td>\n      <td>6.270110</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='601' max='1062' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 601/1062 3:46:41 < 2:54:28, 0.04 it/s, Epoch 1.69/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Eng Latn Loss</th>\n      <th>Spa Latn Loss</th>\n      <th>Ita Latn Loss</th>\n      <th>Deu Latn Loss</th>\n      <th>Arb Arab Loss</th>\n      <th>Tel Telu Loss</th>\n      <th>Tam Taml Loss</th>\n      <th>Quy Latn Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>3.877200</td>\n      <td>No log</td>\n      <td>5.139099</td>\n      <td>4.662704</td>\n      <td>4.814327</td>\n      <td>4.831931</td>\n      <td>4.995979</td>\n      <td>4.636125</td>\n      <td>4.420599</td>\n      <td>6.300550</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>3.196600</td>\n      <td>No log</td>\n      <td>5.206576</td>\n      <td>4.687542</td>\n      <td>4.879029</td>\n      <td>4.879976</td>\n      <td>5.010794</td>\n      <td>4.662020</td>\n      <td>4.423977</td>\n      <td>6.270110</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>3.678400</td>\n      <td>No log</td>\n      <td>5.307767</td>\n      <td>4.731968</td>\n      <td>4.946666</td>\n      <td>4.941481</td>\n      <td>5.012454</td>\n      <td>4.689486</td>\n      <td>4.434676</td>\n      <td>6.220406</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='714' max='1062' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 714/1062 4:43:23 < 2:18:30, 0.04 it/s, Epoch 2.01/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Eng Latn Loss</th>\n      <th>Spa Latn Loss</th>\n      <th>Ita Latn Loss</th>\n      <th>Deu Latn Loss</th>\n      <th>Arb Arab Loss</th>\n      <th>Tel Telu Loss</th>\n      <th>Tam Taml Loss</th>\n      <th>Quy Latn Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>3.877200</td>\n      <td>No log</td>\n      <td>5.139099</td>\n      <td>4.662704</td>\n      <td>4.814327</td>\n      <td>4.831931</td>\n      <td>4.995979</td>\n      <td>4.636125</td>\n      <td>4.420599</td>\n      <td>6.300550</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>3.196600</td>\n      <td>No log</td>\n      <td>5.206576</td>\n      <td>4.687542</td>\n      <td>4.879029</td>\n      <td>4.879976</td>\n      <td>5.010794</td>\n      <td>4.662020</td>\n      <td>4.423977</td>\n      <td>6.270110</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>3.678400</td>\n      <td>No log</td>\n      <td>5.307767</td>\n      <td>4.731968</td>\n      <td>4.946666</td>\n      <td>4.941481</td>\n      <td>5.012454</td>\n      <td>4.689486</td>\n      <td>4.434676</td>\n      <td>6.220406</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='801' max='1062' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 801/1062 4:58:23 < 1:37:28, 0.04 it/s, Epoch 2.26/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Eng Latn Loss</th>\n      <th>Spa Latn Loss</th>\n      <th>Ita Latn Loss</th>\n      <th>Deu Latn Loss</th>\n      <th>Arb Arab Loss</th>\n      <th>Tel Telu Loss</th>\n      <th>Tam Taml Loss</th>\n      <th>Quy Latn Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>3.877200</td>\n      <td>No log</td>\n      <td>5.139099</td>\n      <td>4.662704</td>\n      <td>4.814327</td>\n      <td>4.831931</td>\n      <td>4.995979</td>\n      <td>4.636125</td>\n      <td>4.420599</td>\n      <td>6.300550</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>3.196600</td>\n      <td>No log</td>\n      <td>5.206576</td>\n      <td>4.687542</td>\n      <td>4.879029</td>\n      <td>4.879976</td>\n      <td>5.010794</td>\n      <td>4.662020</td>\n      <td>4.423977</td>\n      <td>6.270110</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>3.678400</td>\n      <td>No log</td>\n      <td>5.307767</td>\n      <td>4.731968</td>\n      <td>4.946666</td>\n      <td>4.941481</td>\n      <td>5.012454</td>\n      <td>4.689486</td>\n      <td>4.434676</td>\n      <td>6.220406</td>\n    </tr>\n  </tbody>\n</table><p>\n    <div>\n      \n      <progress value='11' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 11/125 00:17 < 03:21, 0.56 it/s]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='801' max='1062' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 801/1062 4:58:23 < 1:37:28, 0.04 it/s, Epoch 2.26/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Eng Latn Loss</th>\n      <th>Spa Latn Loss</th>\n      <th>Ita Latn Loss</th>\n      <th>Deu Latn Loss</th>\n      <th>Arb Arab Loss</th>\n      <th>Tel Telu Loss</th>\n      <th>Tam Taml Loss</th>\n      <th>Quy Latn Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>3.877200</td>\n      <td>No log</td>\n      <td>5.139099</td>\n      <td>4.662704</td>\n      <td>4.814327</td>\n      <td>4.831931</td>\n      <td>4.995979</td>\n      <td>4.636125</td>\n      <td>4.420599</td>\n      <td>6.300550</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>3.196600</td>\n      <td>No log</td>\n      <td>5.206576</td>\n      <td>4.687542</td>\n      <td>4.879029</td>\n      <td>4.879976</td>\n      <td>5.010794</td>\n      <td>4.662020</td>\n      <td>4.423977</td>\n      <td>6.270110</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>3.678400</td>\n      <td>No log</td>\n      <td>5.307767</td>\n      <td>4.731968</td>\n      <td>4.946666</td>\n      <td>4.941481</td>\n      <td>5.012454</td>\n      <td>4.689486</td>\n      <td>4.434676</td>\n      <td>6.220406</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>3.320700</td>\n      <td>No log</td>\n      <td>5.381832</td>\n      <td>4.768534</td>\n      <td>4.988316</td>\n      <td>4.988153</td>\n      <td>5.026425</td>\n      <td>4.709599</td>\n      <td>4.444465</td>\n      <td>6.205238</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1001' max='1062' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1001/1062 6:07:04 < 22:24, 0.05 it/s, Epoch 2.82/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Eng Latn Loss</th>\n      <th>Spa Latn Loss</th>\n      <th>Ita Latn Loss</th>\n      <th>Deu Latn Loss</th>\n      <th>Arb Arab Loss</th>\n      <th>Tel Telu Loss</th>\n      <th>Tam Taml Loss</th>\n      <th>Quy Latn Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>3.877200</td>\n      <td>No log</td>\n      <td>5.139099</td>\n      <td>4.662704</td>\n      <td>4.814327</td>\n      <td>4.831931</td>\n      <td>4.995979</td>\n      <td>4.636125</td>\n      <td>4.420599</td>\n      <td>6.300550</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>3.196600</td>\n      <td>No log</td>\n      <td>5.206576</td>\n      <td>4.687542</td>\n      <td>4.879029</td>\n      <td>4.879976</td>\n      <td>5.010794</td>\n      <td>4.662020</td>\n      <td>4.423977</td>\n      <td>6.270110</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>3.678400</td>\n      <td>No log</td>\n      <td>5.307767</td>\n      <td>4.731968</td>\n      <td>4.946666</td>\n      <td>4.941481</td>\n      <td>5.012454</td>\n      <td>4.689486</td>\n      <td>4.434676</td>\n      <td>6.220406</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>3.320700</td>\n      <td>No log</td>\n      <td>5.381832</td>\n      <td>4.768534</td>\n      <td>4.988316</td>\n      <td>4.988153</td>\n      <td>5.026425</td>\n      <td>4.709599</td>\n      <td>4.444465</td>\n      <td>6.205238</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>3.446100</td>\n      <td>No log</td>\n      <td>5.417552</td>\n      <td>4.788678</td>\n      <td>5.015732</td>\n      <td>5.013163</td>\n      <td>5.035207</td>\n      <td>4.715150</td>\n      <td>4.447172</td>\n      <td>6.195675</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1063' max='1062' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1062/1062 6:51:27, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Eng Latn Loss</th>\n      <th>Spa Latn Loss</th>\n      <th>Ita Latn Loss</th>\n      <th>Deu Latn Loss</th>\n      <th>Arb Arab Loss</th>\n      <th>Tel Telu Loss</th>\n      <th>Tam Taml Loss</th>\n      <th>Quy Latn Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>3.877200</td>\n      <td>No log</td>\n      <td>5.139099</td>\n      <td>4.662704</td>\n      <td>4.814327</td>\n      <td>4.831931</td>\n      <td>4.995979</td>\n      <td>4.636125</td>\n      <td>4.420599</td>\n      <td>6.300550</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>3.196600</td>\n      <td>No log</td>\n      <td>5.206576</td>\n      <td>4.687542</td>\n      <td>4.879029</td>\n      <td>4.879976</td>\n      <td>5.010794</td>\n      <td>4.662020</td>\n      <td>4.423977</td>\n      <td>6.270110</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>3.678400</td>\n      <td>No log</td>\n      <td>5.307767</td>\n      <td>4.731968</td>\n      <td>4.946666</td>\n      <td>4.941481</td>\n      <td>5.012454</td>\n      <td>4.689486</td>\n      <td>4.434676</td>\n      <td>6.220406</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>3.320700</td>\n      <td>No log</td>\n      <td>5.381832</td>\n      <td>4.768534</td>\n      <td>4.988316</td>\n      <td>4.988153</td>\n      <td>5.026425</td>\n      <td>4.709599</td>\n      <td>4.444465</td>\n      <td>6.205238</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>3.446100</td>\n      <td>No log</td>\n      <td>5.417552</td>\n      <td>4.788678</td>\n      <td>5.015732</td>\n      <td>5.013163</td>\n      <td>5.035207</td>\n      <td>4.715150</td>\n      <td>4.447172</td>\n      <td>6.195675</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1062' max='1062' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1062/1062 6:52:47, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Eng Latn Loss</th>\n      <th>Spa Latn Loss</th>\n      <th>Ita Latn Loss</th>\n      <th>Deu Latn Loss</th>\n      <th>Arb Arab Loss</th>\n      <th>Tel Telu Loss</th>\n      <th>Tam Taml Loss</th>\n      <th>Quy Latn Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>3.877200</td>\n      <td>No log</td>\n      <td>5.139099</td>\n      <td>4.662704</td>\n      <td>4.814327</td>\n      <td>4.831931</td>\n      <td>4.995979</td>\n      <td>4.636125</td>\n      <td>4.420599</td>\n      <td>6.300550</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>3.196600</td>\n      <td>No log</td>\n      <td>5.206576</td>\n      <td>4.687542</td>\n      <td>4.879029</td>\n      <td>4.879976</td>\n      <td>5.010794</td>\n      <td>4.662020</td>\n      <td>4.423977</td>\n      <td>6.270110</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>3.678400</td>\n      <td>No log</td>\n      <td>5.307767</td>\n      <td>4.731968</td>\n      <td>4.946666</td>\n      <td>4.941481</td>\n      <td>5.012454</td>\n      <td>4.689486</td>\n      <td>4.434676</td>\n      <td>6.220406</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>3.320700</td>\n      <td>No log</td>\n      <td>5.381832</td>\n      <td>4.768534</td>\n      <td>4.988316</td>\n      <td>4.988153</td>\n      <td>5.026425</td>\n      <td>4.709599</td>\n      <td>4.444465</td>\n      <td>6.205238</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>3.446100</td>\n      <td>No log</td>\n      <td>5.417552</td>\n      <td>4.788678</td>\n      <td>5.015732</td>\n      <td>5.013163</td>\n      <td>5.035207</td>\n      <td>4.715150</td>\n      <td>4.447172</td>\n      <td>6.195675</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='16381.026 MB of 34581.274 MB uploaded (84.518 MB deduped)\\r'), FloatProgress(valueâ¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3241b38c4c3d47e991949928837aa04d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (TransientError), entering retry loop.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/arb_Arab_loss</td><td>âââââ</td></tr><tr><td>eval/arb_Arab_runtime</td><td>âââââ</td></tr><tr><td>eval/arb_Arab_samples_per_second</td><td>âââââ</td></tr><tr><td>eval/arb_Arab_steps_per_second</td><td>âââââ</td></tr><tr><td>eval/deu_Latn_loss</td><td>âââââ</td></tr><tr><td>eval/deu_Latn_runtime</td><td>âââââ</td></tr><tr><td>eval/deu_Latn_samples_per_second</td><td>âââââ</td></tr><tr><td>eval/deu_Latn_steps_per_second</td><td>âââââ</td></tr><tr><td>eval/eng_Latn_loss</td><td>âââââ</td></tr><tr><td>eval/eng_Latn_runtime</td><td>âââââ</td></tr><tr><td>eval/eng_Latn_samples_per_second</td><td>âââââ</td></tr><tr><td>eval/eng_Latn_steps_per_second</td><td>âââââ</td></tr><tr><td>eval/ita_Latn_loss</td><td>âââââ</td></tr><tr><td>eval/ita_Latn_runtime</td><td>âââââ</td></tr><tr><td>eval/ita_Latn_samples_per_second</td><td>âââââ</td></tr><tr><td>eval/ita_Latn_steps_per_second</td><td>âââââ</td></tr><tr><td>eval/quy_Latn_loss</td><td>âââââ</td></tr><tr><td>eval/quy_Latn_runtime</td><td>âââââ</td></tr><tr><td>eval/quy_Latn_samples_per_second</td><td>âââââ</td></tr><tr><td>eval/quy_Latn_steps_per_second</td><td>âââââ</td></tr><tr><td>eval/spa_Latn_loss</td><td>âââââ</td></tr><tr><td>eval/spa_Latn_runtime</td><td>âââââ</td></tr><tr><td>eval/spa_Latn_samples_per_second</td><td>âââââ</td></tr><tr><td>eval/spa_Latn_steps_per_second</td><td>âââââ</td></tr><tr><td>eval/tam_Taml_loss</td><td>âââââ</td></tr><tr><td>eval/tam_Taml_runtime</td><td>âââââ</td></tr><tr><td>eval/tam_Taml_samples_per_second</td><td>âââââ</td></tr><tr><td>eval/tam_Taml_steps_per_second</td><td>âââââ</td></tr><tr><td>eval/tel_Telu_loss</td><td>âââââ</td></tr><tr><td>eval/tel_Telu_runtime</td><td>âââââ</td></tr><tr><td>eval/tel_Telu_samples_per_second</td><td>âââââ</td></tr><tr><td>eval/tel_Telu_steps_per_second</td><td>âââââ</td></tr><tr><td>train/epoch</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>train/global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>train/grad_norm</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>train/learning_rate</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>train/loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>train/total_flos</td><td>â</td></tr><tr><td>train/train_loss</td><td>â</td></tr><tr><td>train/train_runtime</td><td>â</td></tr><tr><td>train/train_samples_per_second</td><td>â</td></tr><tr><td>train/train_steps_per_second</td><td>â</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/arb_Arab_loss</td><td>5.03521</td></tr><tr><td>eval/arb_Arab_runtime</td><td>245.9169</td></tr><tr><td>eval/arb_Arab_samples_per_second</td><td>4.054</td></tr><tr><td>eval/arb_Arab_steps_per_second</td><td>0.508</td></tr><tr><td>eval/deu_Latn_loss</td><td>5.01316</td></tr><tr><td>eval/deu_Latn_runtime</td><td>231.2773</td></tr><tr><td>eval/deu_Latn_samples_per_second</td><td>4.311</td></tr><tr><td>eval/deu_Latn_steps_per_second</td><td>0.54</td></tr><tr><td>eval/eng_Latn_loss</td><td>5.41755</td></tr><tr><td>eval/eng_Latn_runtime</td><td>197.881</td></tr><tr><td>eval/eng_Latn_samples_per_second</td><td>5.038</td></tr><tr><td>eval/eng_Latn_steps_per_second</td><td>0.632</td></tr><tr><td>eval/ita_Latn_loss</td><td>5.01573</td></tr><tr><td>eval/ita_Latn_runtime</td><td>235.229</td></tr><tr><td>eval/ita_Latn_samples_per_second</td><td>4.238</td></tr><tr><td>eval/ita_Latn_steps_per_second</td><td>0.531</td></tr><tr><td>eval/quy_Latn_loss</td><td>6.19567</td></tr><tr><td>eval/quy_Latn_runtime</td><td>249.6804</td></tr><tr><td>eval/quy_Latn_samples_per_second</td><td>3.993</td></tr><tr><td>eval/quy_Latn_steps_per_second</td><td>0.501</td></tr><tr><td>eval/spa_Latn_loss</td><td>4.78868</td></tr><tr><td>eval/spa_Latn_runtime</td><td>232.4035</td></tr><tr><td>eval/spa_Latn_samples_per_second</td><td>4.29</td></tr><tr><td>eval/spa_Latn_steps_per_second</td><td>0.538</td></tr><tr><td>eval/tam_Taml_loss</td><td>4.44717</td></tr><tr><td>eval/tam_Taml_runtime</td><td>267.5502</td></tr><tr><td>eval/tam_Taml_samples_per_second</td><td>3.726</td></tr><tr><td>eval/tam_Taml_steps_per_second</td><td>0.467</td></tr><tr><td>eval/tel_Telu_loss</td><td>4.71515</td></tr><tr><td>eval/tel_Telu_runtime</td><td>256.7125</td></tr><tr><td>eval/tel_Telu_samples_per_second</td><td>3.884</td></tr><tr><td>eval/tel_Telu_steps_per_second</td><td>0.487</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>1062</td></tr><tr><td>train/grad_norm</td><td>2.7202</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>3.7317</td></tr><tr><td>train/total_flos</td><td>1972560275177472.0</td></tr><tr><td>train/train_loss</td><td>3.49676</td></tr><tr><td>train/train_runtime</td><td>24701.2463</td></tr><tr><td>train/train_samples_per_second</td><td>0.344</td></tr><tr><td>train/train_steps_per_second</td><td>0.043</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">FullFT_1</strong> at: <a href='https://wandb.ai/aleksey-morshnev/XGLM%20finetuning/runs/jy0x1won' target=\"_blank\">https://wandb.ai/aleksey-morshnev/XGLM%20finetuning/runs/jy0x1won</a><br/> View job at <a href='https://wandb.ai/aleksey-morshnev/XGLM%20finetuning/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0OTQwMTIyNA==/version_details/v0' target=\"_blank\">https://wandb.ai/aleksey-morshnev/XGLM%20finetuning/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0OTQwMTIyNA==/version_details/v0</a><br/>Synced 6 W&B file(s), 0 media file(s), 70 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20240316_011841-jy0x1won/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "trainer.train()\n",
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T15:39:15.602990Z",
     "start_time": "2024-03-16T00:19:22.086815Z"
    }
   },
   "id": "3200e80155a75c9c",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./pretrained_FFT_1\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T00:09:57.243585Z",
     "start_time": "2024-03-17T00:09:34.042782Z"
    }
   },
   "id": "2acfd6f2d34139d1",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T00:29:22.142763Z",
     "start_time": "2024-03-17T00:29:21.368281Z"
    }
   },
   "id": "efaeae44911271f1",
   "execution_count": 49
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
